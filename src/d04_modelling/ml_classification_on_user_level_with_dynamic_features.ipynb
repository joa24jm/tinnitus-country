{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4680060e",
   "metadata": {},
   "source": [
    "# Momentary tinnitus with a user split approach\n",
    "How do the machine learning classification results vary, if we create a sub_df containing only the users in `(10, 4000]` and split on a *user_level*, i.e. one user id goes into training but is excluded from testing and vice versa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbfc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project location\n",
    "p_loc = 'C:/Users/joa24jm/Documents/tinnitus-country/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32bcf0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8d0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utilities as u\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5567d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dfs\n",
    "df = pd.read_csv(p_loc + 'data/03_processed/df_equal_splits_with_age_with_question2_question_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2516fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map filled_out_bins to column 'user_id' to create a groupby object\n",
    "dic = dict(zip(df.user_id.value_counts().index, df.user_id.value_counts().values))\n",
    "df['filled_out_questionnaires'] = df['user_id'].map(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f490e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only users that have more than 10 filled out questionnaires\n",
    "df = df[(df.filled_out_questionnaires > 100) & (df.filled_out_questionnaires <= 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713fc882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64527, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40cf9247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% select features and target\n",
    "features = ['question4', 'question5', 'question6', 'question7',\n",
    "            'user_id']      # EMAs\n",
    "\n",
    "X = df[features] # all columns except for the last\n",
    "y = df['question1']  # Did you perceive the tinnitus right now? -> Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f4332",
   "metadata": {},
   "source": [
    "Ignore the warning, operation works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63c7b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create groups of user ids for a grouped kfold crossvalidation\n",
    "groups = np.array(df['user_id'].tolist())\n",
    "group_kfold = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c470529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split users randomly into train and test users\n",
    "user_ids = df.user_id.unique()\n",
    "test_size = 0.2\n",
    "# random.seed(42)\n",
    "train_users = random.sample(set(user_ids), k=int(len(user_ids)*(1-test_size)))\n",
    "test_users = list(set(user_ids) - set(train_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e0a1f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if train_users and test_users are distinct\n",
    "len(user_ids) == len(set(train_users) | set(test_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfc2930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Train shape before re-sampling:  (51600, 25)\n",
      "Test shape before re-sampling:  (12927, 25)\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.577719   0.249318   0.257035   0.567658  3549.865126\n",
      "std    0.199863   0.209179   0.221221   0.306951  2222.212328\n",
      "\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.540039   0.292274   0.290509   0.508250  3451.791425\n",
      "std    0.238301   0.257115   0.262080   0.319522  1970.293779\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy:\t 0.5329553508150248\n",
      "Confusion Matrix\n",
      "              Tinnitus NO  Tinnitus YES\n",
      "Tinnitus NO          1908          5147\n",
      "Tinnitus YES         1443          5612\n",
      "##################################\n",
      "Fold  2\n",
      "Train shape before re-sampling:  (51601, 25)\n",
      "Test shape before re-sampling:  (12926, 25)\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.561990   0.251799   0.270186   0.538188  3511.773452\n",
      "std    0.207826   0.216835   0.223182   0.310696  2111.298487\n",
      "\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.600447   0.282158   0.238915   0.620774  3584.549734\n",
      "std    0.208944   0.232188   0.255598   0.300026  2419.590999\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy:\t 0.608212927756654\n",
      "Confusion Matrix\n",
      "              Tinnitus NO  Tinnitus YES\n",
      "Tinnitus NO          2758          3817\n",
      "Tinnitus YES         1335          5240\n",
      "##################################\n",
      "Fold  3\n",
      "Train shape before re-sampling:  (51601, 25)\n",
      "Test shape before re-sampling:  (12926, 25)\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.570150   0.261930   0.265135   0.559010  3596.934265\n",
      "std    0.212892   0.222247   0.238900   0.313233  2234.189682\n",
      "\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.567281   0.241583   0.260745   0.537200  3268.658602\n",
      "std    0.193969   0.212437   0.196967   0.299364  1886.595308\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy:\t 0.5569839664885166\n",
      "Confusion Matrix\n",
      "              Tinnitus NO  Tinnitus YES\n",
      "Tinnitus NO          2379          4544\n",
      "Tinnitus YES         1590          5333\n",
      "##################################\n",
      "Fold  4\n",
      "Train shape before re-sampling:  (51602, 25)\n",
      "Test shape before re-sampling:  (12925, 25)\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.572673   0.256311   0.268413   0.558200  3499.305040\n",
      "std    0.215386   0.223917   0.233660   0.311233  2115.334485\n",
      "\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.557235   0.261386   0.242593   0.534580  3580.174559\n",
      "std    0.178671   0.203642   0.215455   0.309738  2408.611074\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy:\t 0.5373134328358209\n",
      "Confusion Matrix\n",
      "              Tinnitus NO  Tinnitus YES\n",
      "Tinnitus NO          2167          5203\n",
      "Tinnitus YES         1617          5753\n",
      "##################################\n",
      "Fold  5\n",
      "Train shape before re-sampling:  (51704, 25)\n",
      "Test shape before re-sampling:  (12823, 25)\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.565088   0.268904   0.259943   0.550790  3473.245192\n",
      "std    0.207287   0.227371   0.235622   0.309723  2196.086224\n",
      "\n",
      "      question4  question5  question6  question7      user_id\n",
      "mean   0.586665   0.210524   0.280714   0.569311  3673.751918\n",
      "std    0.212603   0.178005   0.210306   0.315347  2081.100240\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Accuracy:\t 0.5738846263142938\n",
      "Confusion Matrix\n",
      "              Tinnitus NO  Tinnitus YES\n",
      "Tinnitus NO          2876          4162\n",
      "Tinnitus YES         1836          5202\n",
      "##################################\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for train_idxs, test_idxs in group_kfold.split(X, y, groups):\n",
    "    \n",
    "    # print to console which at fold we are\n",
    "    cnt = cnt + 1\n",
    "    print('Fold ', cnt)    \n",
    "    \n",
    "    # create train and test df\n",
    "    df_train = df.iloc[train_idxs, :]\n",
    "    df_test = df.iloc[test_idxs, :]\n",
    "    \n",
    "    print('Train shape before re-sampling: ', df_train.shape)\n",
    "    print('Test shape before re-sampling: ', df_test.shape)\n",
    "    \n",
    "\n",
    "    \n",
    "    #%% draw randomly from the stratum with question1 == 0 and add these to the df\n",
    "    # so that question1 becomes equally distributed\n",
    "\n",
    "    # train users\n",
    "    times_to_draw = abs(df_train.question1.value_counts()[1] - df_train.question1.value_counts()[0])\n",
    "    minority_class = df_train.question1.value_counts().idxmin()\n",
    "    sampled_df = df_train[df_train.question1 == minority_class].sample(n=times_to_draw, replace = True)\n",
    "    df_train = df_train.append(sampled_df, ignore_index = True)\n",
    "\n",
    "    # test users\n",
    "    times_to_draw = abs(df_test.question1.value_counts()[1] - df_test.question1.value_counts()[0])\n",
    "    minority_class = df_test.question1.value_counts().idxmin()\n",
    "    sampled_df = df_test[df_test.question1 == minority_class].sample(n=times_to_draw, replace = True)\n",
    "    df_test = df_test.append(sampled_df, ignore_index = True)\n",
    "    \n",
    "    # shuffle data before training\n",
    "    df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # create x and y\n",
    "    x_train = df_train[features] # all columns except for the last\n",
    "    y_train = df_train['question1']  # Did you perceive the tinnitus right now? -> Classification problem\n",
    "\n",
    "    x_test = df_test[features]\n",
    "    y_test = df_test['question1']\n",
    "    \n",
    "    # print info\n",
    "    print(x_train.describe().loc[['mean', 'std'], :])\n",
    "    print()\n",
    "    print(x_test.describe().loc[['mean', 'std'], :])\n",
    "    \n",
    "    # safe date of approach\n",
    "    tday = datetime.datetime.now().strftime('%y_%m_%d_%H_%M')\n",
    "\n",
    "    clfs = [GradientBoostingClassifier()]\n",
    "\n",
    "    # use the optimum parameters from the grid_search as reported in the country paper\n",
    "    params_gb = {'learning_rate': [0.5], # helps for inbalanced classes as we have, maybe something like a learning rate?\n",
    "                'max_depth': [10],\n",
    "                'verbose': [0],\n",
    "                'random_state' : [42],\n",
    "                'subsample': [1],\n",
    "                'min_samples_leaf': [1],\n",
    "                'max_features': [.75]\n",
    "                } \n",
    "\n",
    "    # safe params into a list of params to loop over\n",
    "    param_grids = [params_gb]\n",
    "\n",
    "    # set up scores\n",
    "    scores = {'gb': None}\n",
    "\n",
    "    # save trained clfs\n",
    "    trained_clfs= []\n",
    "    \n",
    "    for param_grid, clf, key in zip(param_grids, clfs, scores.keys()):\n",
    "        gridsearch = GridSearchCV(estimator = clf, \n",
    "                                  param_grid = param_grid,\n",
    "                                  scoring = 'accuracy',\n",
    "                                  n_jobs = -1,\n",
    "                                  cv = 3,\n",
    "                                  refit = True,\n",
    "                                  verbose = 2)\n",
    "\n",
    "        # perform gridsearch on train data\n",
    "        gridsearch.fit(x_train, y_train)\n",
    "\n",
    "        # refit best estimator\n",
    "        gridsearch.best_estimator_.fit(x_train, y_train)\n",
    "        \n",
    "        # predict on test set\n",
    "        y_pred = gridsearch.best_estimator_.predict(x_test)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        print('Accuracy:\\t', accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        # calculate confusion matrix\n",
    "        print('Confusion Matrix')\n",
    "        labels = ['Tinnitus NO', 'Tinnitus YES']\n",
    "        print(pd.DataFrame(confusion_matrix(y_test, y_pred), index = labels, \n",
    "                     columns = labels))\n",
    "        \n",
    "        print('##################################')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f728ad",
   "metadata": {},
   "source": [
    "### Poor accuracy in the % 50s if we split on a user level, even for a grouped 5 fold validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0facb90f",
   "metadata": {},
   "source": [
    "Keeping the dynamic questions and predict momentary tinnitus with a user split leads to poor accuracy, no matter which users we choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f1679",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/reighns/groupkfold-and-stratified-groupkfold-efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aab8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
